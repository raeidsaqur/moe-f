#=== GENERATING RESULTS FOR ALL MODELS ===#
==================================================
MODEL: Llama-2-7b-chat-hf (average = weighted): 
Llama-2-7b-chat-hf_seed_42
--------------------------------------------------
+-----------+---------------------+
|   Metric  |        Value        |
+-----------+---------------------+
|  F1 Score | 0.22445851102485767 |
|  Accuracy | 0.26813880126182965 |
| Precision |  0.3457464730508854 |
|   Recall  | 0.26813880126182965 |
+-----------+---------------------+
Performance Report: 
{'Fall': {'f1-score': 0.3536977491961415,
          'precision': 0.23109243697478993,
          'recall': 0.7534246575342466,
          'support': 73.0},
 'Neutral': {'f1-score': 0.20105820105820107,
             'precision': 0.41304347826086957,
             'recall': 0.13286713286713286,
             'support': 143.0},
 'Rise': {'f1-score': 0.16417910447761194,
          'precision': 0.3333333333333333,
          'recall': 0.10891089108910891,
          'support': 101.0},
 'accuracy': 0.26813880126182965,
 'macro avg': {'f1-score': 0.23964501824398485,
               'precision': 0.32582308285633094,
               'recall': 0.3317342271634961,
               'support': 317.0},
 'weighted avg': {'f1-score': 0.22445851102485767,
                  'precision': 0.3457464730508854,
                  'recall': 0.26813880126182965,
                  'support': 317.0}}
--------------------------------------------------
==================================================
==================================================
MODEL: Llama-2-70b-chat-hf (average = weighted): 
Llama-2-70b-chat-hf_seed_42
--------------------------------------------------
+-----------+---------------------+
|   Metric  |        Value        |
+-----------+---------------------+
|  F1 Score | 0.33035851912704484 |
|  Accuracy |  0.3722397476340694 |
| Precision | 0.32637260145146585 |
|   Recall  |  0.3722397476340694 |
+-----------+---------------------+
Performance Report: 
{'Fall': {'f1-score': 0.047619047619047616,
          'precision': 0.18181818181818182,
          'recall': 0.0273972602739726,
          'support': 73.0},
 'Neutral': {'f1-score': 0.514792899408284,
             'precision': 0.4461538461538462,
             'recall': 0.6083916083916084,
             'support': 143.0},
 'Rise': {'f1-score': 0.27358490566037735,
          'precision': 0.26126126126126126,
          'recall': 0.2871287128712871,
          'support': 101.0},
 'accuracy': 0.3722397476340694,
 'macro avg': {'f1-score': 0.2786656175625697,
               'precision': 0.2964110964110964,
               'recall': 0.3076391938456227,
               'support': 317.0},
 'weighted avg': {'f1-score': 0.33035851912704484,
                  'precision': 0.32637260145146585,
                  'recall': 0.3722397476340694,
                  'support': 317.0}}
--------------------------------------------------
==================================================
==================================================
MODEL: Meta-Llama-3-8B-Instruct (average = weighted): 
Meta-Llama-3-8B-Instruct_seed_42
--------------------------------------------------
+-----------+---------------------+
|   Metric  |        Value        |
+-----------+---------------------+
|  F1 Score | 0.34457888121817254 |
|  Accuracy |  0.3911671924290221 |
| Precision |  0.3127592536059006 |
|   Recall  |  0.3911671924290221 |
+-----------+---------------------+
Performance Report: 
{'Fall': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 73.0},
 'Neutral': {'f1-score': 0.4899328859060403,
             'precision': 0.47096774193548385,
             'recall': 0.5104895104895105,
             'support': 143.0},
 'Rise': {'f1-score': 0.38783269961977185,
          'precision': 0.3148148148148148,
          'recall': 0.504950495049505,
          'support': 101.0},
 'accuracy': 0.3911671924290221,
 'macro avg': {'f1-score': 0.29258852850860406,
               'precision': 0.26192751891676624,
               'recall': 0.3384800018463385,
               'support': 317.0},
 'weighted avg': {'f1-score': 0.34457888121817254,
                  'precision': 0.3127592536059006,
                  'recall': 0.3911671924290221,
                  'support': 317.0}}
--------------------------------------------------
==================================================
==================================================
MODEL: Meta-Llama-3-70B-Instruct (average = weighted): 
Meta-Llama-3-70B-Instruct_seed_42
--------------------------------------------------
+-----------+---------------------+
|   Metric  |        Value        |
+-----------+---------------------+
|  F1 Score | 0.19972219126407992 |
|  Accuracy |  0.2996845425867508 |
| Precision | 0.32123892811836946 |
|   Recall  |  0.2996845425867508 |
+-----------+---------------------+
Performance Report: 
{'Fall': {'f1-score': 0.16494845360824742,
          'precision': 0.3333333333333333,
          'recall': 0.1095890410958904,
          'support': 73.0},
 'Neutral': {'f1-score': 0.05161290322580645,
             'precision': 0.3333333333333333,
             'recall': 0.027972027972027972,
             'support': 143.0},
 'Rise': {'f1-score': 0.43455497382198954,
          'precision': 0.29537366548042704,
          'recall': 0.8217821782178217,
          'support': 101.0},
 'accuracy': 0.2996845425867508,
 'macro avg': {'f1-score': 0.2170387768853478,
               'precision': 0.32068011071569785,
               'recall': 0.31978108242858005,
               'support': 317.0},
 'weighted avg': {'f1-score': 0.19972219126407992,
                  'precision': 0.32123892811836946,
                  'recall': 0.2996845425867508,
                  'support': 317.0}}
--------------------------------------------------
==================================================
==================================================
MODEL: Mixtral-8x7B-Instruct-v0.1 (average = weighted): 
Mixtral-8x7B-Instruct-v0.1_seed_42
--------------------------------------------------
+-----------+--------------------+
|   Metric  |       Value        |
+-----------+--------------------+
|  F1 Score | 0.338286014721346  |
|  Accuracy | 0.334384858044164  |
| Precision | 0.3629206606973919 |
|   Recall  | 0.334384858044164  |
+-----------+--------------------+
Performance Report: 
{'Fall': {'f1-score': 0.2916666666666667,
          'precision': 0.29577464788732394,
          'recall': 0.2876712328767123,
          'support': 73.0},
 'Neutral': {'f1-score': 0.375,
             'precision': 0.4639175257731959,
             'recall': 0.3146853146853147,
             'support': 143.0},
 'Rise': {'f1-score': 0.32,
          'precision': 0.2684563758389262,
          'recall': 0.39603960396039606,
          'support': 101.0},
 'accuracy': 0.334384858044164,
 'macro avg': {'f1-score': 0.32888888888888895,
               'precision': 0.342716183166482,
               'recall': 0.332798717174141,
               'support': 317.0},
 'weighted avg': {'f1-score': 0.338286014721346,
                  'precision': 0.3629206606973919,
                  'recall': 0.334384858044164,
                  'support': 317.0}}
--------------------------------------------------
==================================================
==================================================
MODEL: dbrx-instruct (average = weighted): 
dbrx-instruct_seed_42
--------------------------------------------------
+-----------+---------------------+
|   Metric  |        Value        |
+-----------+---------------------+
|  F1 Score | 0.33717546005137633 |
|  Accuracy | 0.33753943217665616 |
| Precision |  0.3563378418070651 |
|   Recall  | 0.33753943217665616 |
+-----------+---------------------+
Performance Report: 
{'Fall': {'f1-score': 0.2,
          'precision': 0.22807017543859648,
          'recall': 0.1780821917808219,
          'support': 73.0},
 'Neutral': {'f1-score': 0.4016064257028112,
             'precision': 0.4716981132075472,
             'recall': 0.34965034965034963,
             'support': 143.0},
 'Rise': {'f1-score': 0.34509803921568627,
          'precision': 0.2857142857142857,
          'recall': 0.43564356435643564,
          'support': 101.0},
 'accuracy': 0.33753943217665616,
 'macro avg': {'f1-score': 0.31556815497283247,
               'precision': 0.3284941914534764,
               'recall': 0.32112536859586904,
               'support': 317.0},
 'weighted avg': {'f1-score': 0.33717546005137633,
                  'precision': 0.3563378418070651,
                  'recall': 0.33753943217665616,
                  'support': 317.0}}
--------------------------------------------------
==================================================
==================================================
MODEL: OpenAI-gpt-4o (average = weighted): 
OpenAI-gpt-4o_seed_42
--------------------------------------------------
+-----------+---------------------+
|   Metric  |        Value        |
+-----------+---------------------+
|  F1 Score |  0.3374617939801993 |
|  Accuracy | 0.36908517350157727 |
| Precision | 0.33301080155253865 |
|   Recall  | 0.36908517350157727 |
+-----------+---------------------+
Performance Report: 
{'Fall': {'f1-score': 0.2631578947368421,
          'precision': 0.25316455696202533,
          'recall': 0.273972602739726,
          'support': 73.0},
 'Neutral': {'f1-score': 0.5163204747774481,
             'precision': 0.4484536082474227,
             'recall': 0.6083916083916084,
             'support': 143.0},
 'Rise': {'f1-score': 0.13793103448275862,
          'precision': 0.22727272727272727,
          'recall': 0.09900990099009901,
          'support': 101.0},
 'accuracy': 0.36908517350157727,
 'macro avg': {'f1-score': 0.30580313466568293,
               'precision': 0.3096302974940584,
               'recall': 0.32712470404047783,
               'support': 317.0},
 'weighted avg': {'f1-score': 0.3374617939801993,
                  'precision': 0.33301080155253865,
                  'recall': 0.36908517350157727,
                  'support': 317.0}}
--------------------------------------------------
==================================================
#=== END - GENERATING RESULTS FOR ALL MODELS ===#
